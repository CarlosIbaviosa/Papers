---
title             : "The Effect of Image Presentation Rate on Person Identification"
shorttitle        : "Image Presentation Rate and Person Identification"

author: 
  - name          : "Carlos M. Ibaviosa"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : " "
    email         : "carlos.ibaviosa@gmail.com"
  - name          : "Rachel A. Searston"
    affiliation   : "1,2"

affiliation:
  - id            : "1"
    institution   : "University of Adelaide"
  - id            : "2"
    institution   : "University of Adelaide"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  Our ability to recognise complex images across contexts depends on our exposure to similar instances. For example, despite much natural variation, it is easier to recognise a new instance of a familiar face than an unfamiliar face. As we encounter similar images, we automatically notice structural commonalities and form a representation of how the image generally looks, even when each image is presented rapidly (i.e., several milliseconds each). However, it is not clear whether this process allows us to better identify new instances of an image compared to assessing single images for a longer duration. Across two experiments, I tested observers’ person recognition ability when presented with rapid image streams at varying rates compared to a single image. Experiment 1 compares performance between upright and inverted faces. Experiment 2 compares performance between fingerprints from the same finger and from the same person more generally. My results suggest that viewing images rapidly is better than single images when identifying faces, but not fingerprints; and that people better recognise upright compared to inverted faces, but are similar in both fingerprint conditions. I discuss the theoretical implications of these results, as well as some practical implications in security and forensic contexts.

  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Visual cognition, recognition, gist perception, ensemble coding, face processing, fingerprint analysis"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

\tableofcontents
\newpage

```{r setup, include = FALSE}
library("papaja")
library(knitr)
options(digits=3)
library(tidyverse) ## All the good things
library(ggbeeswarm) ## Beeswarm plots with ggplot2
library(RColorBrewer) ## Beautiful colour palettes
library(viridis) ## More palettes
library(lawstat) ## Levene's
source("https://bit.ly/2q4XQ66") ## geom_flat_violin()
library(ez) ## Analysis of experimental data
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Significance Statement
Forensic examiners in various fields are regularly required to make identification decisions based on complex, unfamiliar images – such as a stranger’s face, or a stranger’s fingerprint – often based on a single comparison photo, or a limited number of comparison photos. While much evidence suggests that recognising a new image would benefit from viewing multiple different examples of that image beforehand, fewer studies have explored whether it is more beneficial to view several comparison photos quickly, or a single comparison photo for a longer duration, if given a limited time to make the identification. If quickly processing several images leads to greater image recognition, then a similar approach could be used to better allocate time resources, or streamline training in many forensic identification disciplines. In this study, we tested this idea under various different conditions, using face (Experiment 1) and fingerprint (Experiment 2) stimuli, with novice participants. While we speculated on many possible constraints when applying this methodology under different conditions, we generally found that while there was an advantage to quickly viewing several images, this advantage was more pronounced with more familiar image categories, and was slightly affected by image specificity.

# Introduction
\colorbox{yellow}{[Fix up expression]}  
\colorbox{yellow}{[Make sure all links to OSF pages are working]}  
\colorbox{yellow}{[Make sure all references are done...]}

[Open with the kinds of tasks that forensic experts are faced with - and why it's important to focus on high quality training and improving discriminability...]

Our ability to efficiently process and categorise faces seems to depend on how much experience we have in viewing similar kinds of faces in the first place. Although we engage in familiar face recognition everyday, unfamiliar face recognition tends to be much more difficult (references). In some contexts, the same person's face may look very different, or two different faces may sometimes look very similar. For example, on an individual level we can better identify familiar faces compared to unfamiliar faces because we have more exposure to how familiar faces vary across contexts (references). On a categorical level, alternatively, we can better process, identify, and discriminate unfamiliar faces from categories that we are more familiar with. Research into the own-race effect, for example, suggests that we can better identify unfamiliar faces from our own race, compared to faces from other races, given that we tend to have more exposure and experience in processing faces from our own race (reference). If our ability to effectively recognise and categorise different objects, both on an individual and categorical level, is assisted by our understanding of the commonalities between members of a particular category, how then do we make sense of these commonalities? Some theories, such as the exemplar theory (verify), suggest that as we view multiple instances, we compare each new instance to particular instances we have seen in the past, and as we accumulate more experience with varying instances, new instances are more likely to resemble previous instances (reference). Alternatively, some authors suggest that as we accumulate experience with similar instances, we become attuned to the common or average characteristics that become salient over time, and recognise new instances in comparison with the average (reference). Many studies that examine the influence of familiarity on image recognition (both at the individual and category level) give participants ample time to view and encode each individual instance - for example, face recognition studies often give participants several seconds to learn new faces (references), and fingerprint (reference) experts will have spent hours in cumulatively viewing objects in their domain of expertise - and so it is difficult to determine whether becoming familiar with an instance or category depends on encoding individual exemplars, or generating an average. However, it may be possible to identify which of these theories is more influential by examining the process of "ensemble coding".

Ensemble coding refers to our ability to rapidly glean the average properties of a range of similar stimuli to make sense of the common characteristics in our environment \colorbox{yellow}{(references)}. This process is incredibly automatic - in fact, many studies have used the rapid serial visual presentation (RSVP) methodology, where a series of similar images are presented for just several milliseconds each one after the other, to show that we can automatically compute the average representation of all of the images - despite not being able to process any individual image. This finding has been replicated for when participants focus on simple stimuli (e.g., average circle size; reference), complex stimuli (e.g., average facial expression; reference), and even when the RSVP stream is not the main focus of the experiment (reference). However, while ensemble coding is very robust to task demands, and seems linked to how we make sense of image variability in our environment, no studies seem to have established whether presenting unfamiliar images in an RSVP stream can help to identify new images of the same category. If the averaging hypothesis of recognition is true, then this RSVP methodology should yield a similar performance increase as seen in previous studies, despite participants being unable to process the details of individual exemplars. Additionally, if people can indeed learn to recognise new instances of an image when presented with an RSVP stream of similar images, this methodology could potentially help people become more familiar with an image category in a shorter amount of time when compared to examining several images more carefully - potentially helping to streamline the development of expertise with unfamiliar images. Evidence suggests that novices in forensic identification domains may become better accustomed to identifying complex images if they are exposed to more varying exemplars during training (double check if this is true - Thompson & Tangen, 2014), and so the RSVP methodology may be a powerful way to boost familiarity and expertise with an image category in a shorter amount of time. The current study, therefore, asks whether rapidly deriving an ensemble of several images can improve novices' ability to identify unfamiliar objects compared to carefully assessing the details of a single image for the same duration. Across two experiments, we will use unfamiliar face (Experiment 1) and fingerprint (Experiment 2) stimuli to explore this question in a forensic context. We will also explore the possible constraints to this methodology when considering other variables that may influence recognition, such as orientation (Experiment 1) and image specificity (Experiment 2), to explore the limits of what seems to be a robust phenomenon, and build on previous research that has determined constraints in visual identification tasks among experienced participants (Bukach, Phillips & Gauthier, 2010; Diamond & Carey, 1986; see and include Searston & Tangen, 2017).

## The Current Study
The present research examines whether viewing an RSVP stream of images at varying rates can better facilitate object recognition compared to viewing a single image, when presented for an equal duration of time. While several studies on face recognition have already suggested that it is better to view more photos of a person compared to fewer photos (e.g., Murphy et al., 2015), no studies seem to have directly compared whether it is better to carefully assess the details of a single image, or to view the general gist of several images more quickly, when making an identification. Across two experiments, we presented participants with complex, unfamiliar images representing the same person (i.e., a person's face in Experiment 1 or fingerprint in Experiment 2), as either single images, or as RSVP streams at varying rates (i.e., two, four, and eight images per second) for a total of eight seconds. In each trial they were asked whether they viewed images from the same or different category to the test image (e.g., "Is this the same person?"). Based on previous research, we expect that recognition performance will increase as participants view more images per second, given that this would allow them to create richer ensemble representations compared to other conditions. In essence, viewing more images per second may allow participants to become "more familiar" with the unfamiliar stimuli presented, making it easier to recognise any common features shared with the test image and make an appropriate identification or rejection. However, we also expect that while recognition performance may improve when viewing more images, confidence may be higher when viewing *fewer* images, as these conditions would likely feel the most intuitive to participants, and would allow participants to maximise the encoding of any particular details.

In Experiment 1, we examined whether rapidly presenting images of the same face would increase face recognition compared to viewing a single image more carefully. In this experiment, participants viewed the RSVP streams *before* viewing the test image, as previous research suggests \colorbox{yellow}{(references)} that it is the accumulation of multiple previous exemplars that facilitates face recognition. We were also interested in whether recognition in these different conditions is affected by familiarity with the general stimulus class, and so we manipulated familiarity by presenting the faces as upright and inverted images. Previous research in visual recognition has suggested that we are much better at recognising upright faces compared to inverted faces (see Rossion, 2008 for a review) - possibly due to our disproportionate experience in viewing upright faces everyday (references), an innate ability to do so more efficiently (references), or a combination of both. In manipulating face inversion in this experiment, we can examine the influence of ensemble coding in recognition tasks not only on an individual level of familiarity, but on a categorical level: if ensemble coding tends to be automatic and accurate when viewing simple stimuli (e.g., circle size; references) and complex familiar stimuli (e.g., upright faces; references), would it operate the same way when viewing complex *unfamiliar* stimuli (i.e., inverted faces)? It is possible that inverted faces may not share the same benefit as upright faces, as the difficulties in processing inverted faces holistically (Tanaka & Simonyi, 2016; see also Rossion, 2008 for a review) may make it more difficult to process the gist of each image in the stream. However, given how automatic ensemble coding is in a variety of tasks with a variety of stimuli, we believe that our methodology could nevertheless exert a positive influence with face recognition (but see Haberman et al., 2009; Haberman, Lee, & Whitney, 2015; and Leib, Puri, Fischer, Bentin, Whitney, & Robertson, 2012, in relation to ensemble coding generally - what have these studies said???). In fact, we predict that any benefit derived from ensemble coding may actually be more pronounced when viewing inverted compared to upright faces, given that our existing advantage for upright face-matching may limit how beneficial this methodology may be for upright faces relative to inverted faces, which do not share the same constraints.

# Experiment 1
## Methods
The preregistration plan [add link] for this experiment is available on the Open Science Framework (OSF), and includes our predictions and hypotheses, methodology, power analysis, analysis plan, and links to all available materials, software, raw data files, and R markdown scripts. We also ran a similar experiment using fingerprint stimuli, and the predictions and results for that experiment are also available via the same link.

### Participants
30 participants took part in this experiment (19 male, 11 female, mean age of 25) consisting of students from the University of Adelaide and members of the general Adelaide population. All participants were required to be at least 18 years of age, fluent in English, and have normal or corrected-to-normal vision. Participants were incentivised by receiving a $20 Coles/Myer gift card in exchange for their time (see Appendix A). All participants provided informed consent prior to commencing the experiment (see Appendix B).

Participants’ responses were to be excluded if they failed to complete the experiment due to illness, fatigue or excessive response delays (i.e., longer than the session allows). Participants who responded in less than 500ms, or consecutively provided the same response, for over 30 percent of trials were also to be excluded. In these cases, another participant was to be recruited and given the same stimulus set according to the previous participant’s experiment number. None of the 30 participants met any of these pre-specified exclusion criteria.

### Power Analysis
To our knowledge, no previous research has analysed the effect of image presentation rate in a face recognition task. The sample size was determined based on a power analysis assuming a Smallest Effect Size of Interest (SESOI; Lakens, Scheel, Isagar, 2018) of *d* = 0.45 for all effects. Previous studies on face recognition typically show face inversion effect sizes ranging between 0.96 and 1.29 (e.g., Civile, Elchlepp, McLaren, Galang, Lavric, & McLaren, 2018), and so this SESOI was a conservative estimate. With a sample of 30 participants and 96 observations per participant (12 trials x 4 different image presentation rates x 2 levels of image orientation = 96 trials), the experiment had an estimated power of 83.2% to detect a main effect of image presentation rate, and an estimated power of 98.2% to detect an interaction between image presentation rate and orientation. We used Jake Westfall’s PANGEA R Shiny App to calculate power given these design parameters.

### Design
This experiment had a 4 (presentation rate: single image, 2, 4, 8 images per second) x 2 (orientation: upright vs. inverted) fully within-subjects design. In Experiment 1, participants were presented with a series of 96 face streams for eight seconds. Presentation rate varied across the streams, with participants viewing streams of 64 face images for 125 milliseconds each (8 images per second), streams of 32 face images for 250 milliseconds each (4 images per second), streams of 16 images for 500 milliseconds each (2 images per second), and single images of faces for eight seconds. After a brief 500 millisecond delay, a new ‘target’ face image from either the same or different person was displayed and participants indicated on a scale whether they believed this new face was the same or different person as the face in the stream, and their confidence in their decision (see Figure 2).

The faces were presented upright for one half of the trials and inverted on the other half. Both orientation blocks were counterbalanced across participants. The four presentation rate blocks were also randomly presented to each participant within the two orientation blocks. Within each presentation rate block, half of the trials depicted the same person as the target image, and the other half depicted a different person to the target image. These trials were randomly presented for each participant.

\colorbox{yellow}{[Figure 2]}

### Measures.
Participants indicated their judgments on a 12-point forced choice confidence rating scale: 1 to 6 indicates a “Different” response and 7 to 12 a “Same” response, with ratings closer to 1 and 12 indicating higher confidence than ratings closer to 6 or 7 (see Figure 2). This scale allows us to compute participants’ accuracy (mean proportion correct), and mean confidence (between 1 and 6), and has been used in previous research to compute individuals’ discriminability as indicated by the area under their proper Receiver Operating Characteristic (ROC) curve (‘AUC’; Vokey, Tangen, & Cole, 2009).

To measure discriminability, we computed each participant’s AUC for each condition from their cumulative confidence ratings on same and different trials (see Hanley & McNeil, 1982; Vokey, 2016). An AUC of 1 indicates perfect discriminability, and an AUC of .5 indicates chance performance. A large number of ‘hits’ (i.e., participant correctly says “Same”) and a small number of ‘false alarms’ (i.e., participant incorrectly says “Same”) indicates high discriminability and would produce an AUC score closer to 1, whereas an equal number of hits and false alarms would indicate chance discriminability, resulting in lower AUC scores closer to .5. Participants’ confidence is also taken into account in computing AUC, such that lower confidence judgments reflect lower discriminability.

Confidence was computed by collapsing the 12-point rating scale to a 6-point scale. The original scale provided six degrees of confidence for both “Different” (1-6) and “Same” (7-12) responses; and so the collapsed scale isolates confidence by coding all “unsure” responses (6 or 7) to 1, all “moderately unsure” responses (5 or 8) to 2, all “slightly unsure” responses (4 or 9) to 3, and so on—until all “sure” responses (1 or 12) are coded to 6.

### Materials
The faces were sourced from the VGGFace 2 dataset (Cao, Shen, Xie, Parkhi, & Zisserman, 2018). The original set contains 3.31 million images of 9,131 identities collected from Google Image searches. We used a subset [add link] of 9,600 images of 48 identities (200 images per identity). We preserved all natural variation across the images of each identity to increase the difficulty of the target trials (i.e., dissimilar matching identities are more challenging to tell together). The original dataset also contains a large number of blonde, Caucasian, female identities. While this dataset has some limitations (which will be addressed in the discussion), we constrained our subset to this demographic to increase target-distractor similarity. Highly similar, non-matching identities are harder to tell apart; and evidence suggests that female identites are typically perceived as more similar than male identities (e.g., Ramsey et al., 2005) - increasing the difficulty of what could otherwise be an easy task. We further increased similarity by computing the distributional characteristics (mean, min, max of image) of each identity and pairing similar identities side-by-side to increase target-distractor resemblance (see Appendix C).

Ramsey, J. L., Langlois, J. H., & Marti, C. N. (2005). Infant categorization of faces: Ladies first. Developmental Review, 25, 212–246. https://doi-org.proxy.library.adelaide.edu.au/10.1016/j.dr.2005.01.001.


We reduced the original set of images for each identity down to 200 by manually excluding any images with dimensions under 100 x 100 pixels, drawings, illustrations or animations of faces, significantly occluded faces, faces with distracting watermarks, duplicates or images that clearly depicted a different identity. All other original details were left intact, including natural variation in pose, age, illumination, etc. We then cropped each face to a square using a script in Adobe Photoshop CC (version 20.0.4) and centred the images around the eyes as close as possible. To avoid ceiling effects for upright faces, we initially reduced all the images to 64 x 64 pixels, then upsized them to 400 x 400 pixels in MATLAB. However, after pilot testing (N = 2) revealed that the task was still too easy for upright faces (mean proportion correct = .92), we further reduced the images to 32 x 32 pixels. A second pilot (N = 5) then revealed near-chance performance with the inverted faces (mean proportion correct = .59), and so we generated a fresh batch of images reduced to 48 x 48 pixels to avoid ceiling or chance performance in either condition (see Figure 2).

### Software
The video instructions and face recognition task were presented to participants on a 13-inch MacBook Pro, with over-ear headphones. We developed the software used to generate the trial sequences, present stimuli to participants, and record their responses in LiveCode (version 9.0.2; the open source ‘community edition’). The LiveCode source files and experiment code are available in the Software component of the OSF project. The data analytic scripts and plots for this project were produced in RStudio with the R Markdown package. A list of other package dependencies needed to reproduce our plots and analyses are listed in the data visualisation and analysis html file found in the Analyses component of the OSF project.

### Procedure
Participants commenced the task after reading an information sheet, signing a consent form, and watching an instructional video [add link]. Participants rated a total of 96 faces as the same or different identity to the faces in the stream. In each case, they indicated their judgments on the 12-point confidence rating scale. The response buttons remained on screen until participants selected their rating; however, a prompt to respond within 4 seconds was displayed between trials if participants took longer to decide. Corrective feedback in the form of an audio (correct or incorrect tone) and visual (the selected response button turns green or red) cue is presented to participants after every trial. The whole face recognition task took about 25 minutes to complete.


## Results

\colorbox{yellow}{[Report paired comparisons – and any other instances where significant differences would be unlikely…]
[Make sure symbols in stats blocks are all correct - generalised eta squared...]
[insert figures and tables]]
[reference additional files appropriately - appendix or nah?]

The following analysis examines participants' discriminability (AUC) scores and confidence. Raw proportion correct scores reflect the same pattern as discriminability, and can be found in the Appendix.

### Presentation Rate and Orientation
We conducted repeated measures ANOVAs on participants’ AUC scores to test whether their ability to distinguish faces of the same versus different identities significantly increased as presentation rate increased, and whether these effects varied as a function of familiarity with the stimulus orientation. As shown in Table 1, our results suggest that participants are better at recognising faces when viewing rapid streams of the same face compared to single images for both upright and inverted conditions, despite discriminability being lower overall with inverted faces compared to upright faces. A repeated measures ANOVA yielded a significant, medium-to-large (see Cohen, 1988 for conventions) main effect of orientation (F(1, 29) = 68.258, p < .001, G2 = .148) and a significant, small-to-medium main effect of image rate (F(3, 87) = 3.788, p = .013, G2 = .041) on participants’ discriminability scores (see Figure 3). No significant interaction was found (F(3, 87) = 1.952, p = .127, G2 = .019). A treatment-control contrast suggested that when compared to viewing a single image, participants’ discriminability scores significantly improved under all rapid presentation rate conditions (2 images: t = 2.192, p = .029; 4 images: t = 2.468, p = .014; 8 images: t = 2.431, p = .016). A subsequent trend analysis also revealed a significant linear trend over presentation rate conditions (t = 2.394, p = .018). That is, discriminability increased in a linear fashion as a function of increasing presentation rate for both upright and inverted faces, despite inverted faces being harder to recognise.

``` {r, echo = FALSE}
my_data_faces <- read.csv(file="data/my_data_faces.csv", header=TRUE)

acc_data_faces <- my_data_faces %>%
  select(-Confidence, -Milliseconds) %>%
  group_by(Participant, Mode, Orientation, Image_Rate) %>% summarise(
    mean_PC = mean(Accuracy)
  ) %>%
  arrange(Orientation, Image_Rate)

secs_data_faces <- my_data_faces %>%
   select(-Confidence, -Accuracy) %>%
  group_by(Participant, Mode, Orientation, Image_Rate) %>% summarise(
    mean_secs = mean(Milliseconds/1000)
  ) %>%
  arrange(Orientation, Image_Rate)

sum_data_faces<-merge(acc_data_faces, secs_data_faces, by=c("Participant","Mode","Orientation", "Image_Rate"), all=TRUE)

## LINE 1: number of distractors rated x participant
line1Face <- my_data_faces %>%  
  select(-Milliseconds, -Accuracy) %>%
  group_by(Participant, Mode, Orientation, Image_Rate, Trial_Type) %>% 
  mutate(conf1=ifelse(Confidence == 1, 1, 0),
 conf2=ifelse(Confidence == 2, 1, 0),conf3=ifelse(Confidence == 3, 1, 0),
  conf4=ifelse(Confidence == 4, 1, 0),conf5=ifelse(Confidence == 5, 1, 0),
  conf6=ifelse(Confidence == 6, 1, 0),conf7=ifelse(Confidence == 7, 1, 0),
  conf8=ifelse(Confidence == 8, 1, 0),conf9=ifelse(Confidence == 9, 1, 0),
  conf10=ifelse(Confidence == 10, 1, 0),conf11=ifelse(Confidence == 11, 1, 0),
  conf12=ifelse(Confidence == 12, 1, 0)) %>% 
    group_by(Participant, Mode, Orientation, 
                 Image_Rate, Trial_Type) %>%
    select(-c(Confidence, Age)) %>%
    summarise_if(is.numeric, sum) %>%   
    arrange(Trial_Type, Image_Rate, Orientation,  
            Participant, Mode) %>% filter(Trial_Type == "different") %>% 
  gather(Confidence_Rating, Line_1, conf1:conf12)%>%
    select(-Trial_Type)

## LINE 2: number of targets rated > x
line2Face <- my_data_faces %>%  
  select(-Milliseconds, -Accuracy) %>%  
  group_by(Participant, Mode, Orientation, Image_Rate, Trial_Type) %>% 
  mutate(conf1=ifelse(Confidence >1, 1, 0),
  conf2=ifelse(Confidence >2, 1, 0),conf3=ifelse(Confidence >3, 1, 0),
  conf4=ifelse(Confidence >4, 1, 0),conf5=ifelse(Confidence >5, 1, 0),
  conf6=ifelse(Confidence >6, 1, 0),conf7=ifelse(Confidence >7, 1, 0),
  conf8=ifelse(Confidence >8, 1, 0),conf9=ifelse(Confidence >9, 1, 0),
  conf10=ifelse(Confidence >10, 1, 0),conf11=ifelse(Confidence >11, 1, 0),
  conf12=ifelse(Confidence >12, 1, 0)) %>% 
    group_by(Participant, Mode, Orientation, 
                 Image_Rate, Trial_Type) %>%
    select(-c(Confidence, Age)) %>%
    summarise_if(is.numeric, sum) %>%   
    arrange(Trial_Type, Image_Rate, Orientation,  
            Participant, Mode) %>% filter (Trial_Type == "same") %>% 
  gather(Confidence_Rating, Line_2, conf1:conf12)%>%
    select(-Trial_Type)

## LINE 3: number of targets rated x per participant
line3Face <- my_data_faces %>%  
  select(-Milliseconds, -Accuracy) %>%  
  group_by(Participant, Mode, Orientation, Image_Rate, Trial_Type) %>% 
  mutate(conf1=ifelse(Confidence == 1, 1, 0),
  conf2=ifelse(Confidence == 2, 1, 0),conf3=ifelse(Confidence == 3, 1, 0),
  conf4=ifelse(Confidence == 4, 1, 0),conf5=ifelse(Confidence == 5, 1, 0),
  conf6=ifelse(Confidence == 6, 1, 0),conf7=ifelse(Confidence == 7, 1, 0),
  conf8=ifelse(Confidence == 8, 1, 0),conf9=ifelse(Confidence == 9, 1, 0),
  conf10=ifelse(Confidence == 10, 1, 0),conf11=ifelse(Confidence == 11, 1, 0),
  conf12=ifelse(Confidence == 12, 1, 0)) %>% 
    group_by(Participant, Mode, Orientation, 
                 Image_Rate, Trial_Type) %>%
    select(-c(Confidence, Age)) %>%
    summarise_if(is.numeric, sum) %>%   
    arrange(Trial_Type, Image_Rate, Orientation,  
            Participant, Mode) %>% filter(Trial_Type == "same") %>% 
  gather(Confidence_Rating, Line_3, conf1:conf12)%>%
    select(-Trial_Type)

## Merge Line 1,2 & 3
confFace<-merge(line1Face, line2Face, by=c("Participant","Mode","Orientation","Image_Rate", "Confidence_Rating"), all=TRUE)
confFace<-merge(confFace, line3Face, by=c("Participant","Mode", "Orientation","Image_Rate", "Confidence_Rating"), all=TRUE)

## LINE 5: line1 * line2 + 0.5 *line1 * line3
confFace <-confFace %>% mutate(Line_5 = Line_1*Line_2+.05*Line_1*Line_3) %>%
   group_by(Participant, Mode, Orientation, Image_Rate) %>%
   summarise_if(is.numeric, sum)

## Compute AUC (or Wilcoxon's W)
AUC_data_faces<-confFace %>% mutate(AUC = Line_5/(Line_1*Line_3))%>%
   select(Participant, Mode, Orientation, Image_Rate, AUC)

sum_data_faces<-merge(sum_data_faces, AUC_data_faces, by=c("Participant","Mode", "Orientation", "Image_Rate"), all=TRUE)

sum_data_faces$Orientation = factor(sum_data_faces$Orientation,levels = c("upright","inverted"), ordered = FALSE)
sum_data_faces$Image_Rate = factor(sum_data_faces$Image_Rate,levels = c("1 image","2 images","4 images","8 images"), ordered = TRUE)

sum_data_faces_p <- sum_data_faces  %>%
  filter(Mode == "participant")

AUC_table <- sum_data_faces_p %>%
  group_by(Orientation, Image_Rate) %>% summarise(
    mean = mean(AUC),
    SD = sd(AUC)
  )

library(kableExtra)

kable(AUC_table) %>%
  add_header_above(c("Mean Discriminability (AUC)" = 4))


PC_table <- sum_data_faces_p %>%
  group_by(Orientation, Image_Rate) %>% summarise(
    mean = mean(mean_PC),
    SD = sd(mean_PC)
  )

kable(PC_table) %>%
  add_header_above(c("Mean Discriminability (PC)" = 4))

```

[figure 3]

To address our prediction that confidence will be highest when viewing single images, we analysed participants’ confidence ratings for each condition. As shown in Table 2, participants were more confident at identifying upright compared to inverted faces, though confidence seems similar across different presentation rates. A repeated measures ANOVA revealed a significant, medium-to-large main effect of orientation (F(1, 29) = 8.655, p = .006, G2 = .020), but no significant main effect of image rate (F(3, 87) = 0.785, p = .505, G2 = .002), and no significant interaction (F(3, 87) = 0.365, p = .779, G2 = .001; see Figure 4). Given that confidence did not significantly differ across image rate conditions, our data did not support the third hypothesis.

\colorbox{yellow}{[table 2]
[figure 4]}

## Discussion
- what are the 3-5 main findings? (plan)
  - RSVP works if actually presented like a normal identification task (for both familiar and less familiar complex objects)
  - RSVP/ensemble coding indeed works with complex, unfamiliar image categories...
  - comment on how this might add to the confidence/accuracy literature
- brief overview of hypotheses and findings (8-10 sentences max) - anything new/original?
  - Averaging hypothesis supported over exemplar hypothesis (particularly at faster image rates)
- few paragraphs dealing with the headline findings and relating it to literature

This experiment aimed to assess whether different RSVP streams could boost face recognition compared with a single image when presented with upright and inverted faces. [comment on how this is a linear increase] In line with previous face-matching literature, our analyses suggest that this is indeed the case. While previous research suggests that RSVP streams allow observers to recognise the average representation of similar items (e.g., Ariely, 2001; De Fockert & Wolfenstein, 2009), the current study also suggests that this ensemble can facilitate the recognition of new instances of the same category. As such, this result seems to support the averaging hypothesis of becoming familiar with a person's face (e.g., Bruce & Young, 1986; Burton & Bruce, 1993), rather than the exemplar hypothesis (references), given that observers would not have the opportunity to encode any individual exemplar into visual memory. [maybe elaborate on this a little, actually look into the research for the exemplar hypothesis]

Our results also suggest that the benefit associated with increasing image rate occurred in a similar manner for both upright and inverted faces, despite inverted faces being harder to recognise overall. While lower performance when recognising inverted faces was expected (see Tanaka & Simonyi, 2016, and Valentine, 1988), it is surprising that the RSVP paradigm influenced both upright and inverted faces equally. Given that we already process upright faces more successfully than inverted faces, we expected that upright image streams may have a relatively smaller benefit over single images when compared to inverted faces. Our results may have been a product of presenting the images at a reduced resolution to prevent ceiling effects. It is possible that this may have lessened the upright face advantage (e.g., Balas, Gable, & Pearson, 2019), allowing the image streams to demonstrate a similar effect for both orientation conditions.


Given that upright and inverted faces differ only in observers’ decreased familiarity with inverted faces (Valentine, 1988), these results suggested that ensemble coding may assist recognition even when exposed to less familiar stimuli.

Surprisingly, we also found no significant differences in confidence ratings across image rates, despite single images allowing the greatest encoding time. Given that identifying different instances of unfamiliar faces has been reported to be a challenging task (e.g., Bruce et al., 1999), which would undoubtedly be harder when the faces are blurred (e.g., Balas et al., 2019; Sanford, Sarker, & Bernier, 2018), it seems likely that the relative disadvantages in either condition (i.e., less familiarity with single images compared to less processing time with several images) may have undermined confidence equally across all conditions.

As previously mentioned, there were some limitations with the face database that we selected. The first is that the selected database sampled faces from Google Images, and so some of the identities depicted celebrities. Although this provided a suitably large sample of naturally varying face images that could not be found in other databases, this may have increased participants’ performance in some trials and inflated our effect sizes, as familiar faces are easier to recognise than unfamiliar faces (Megreya & Burton, 2006). However, given that recognising celebrity faces is also impaired by the face inversion effect \colorbox{yellow}{(references)}, and that most participants self-reported being unfamiliar with the vast majority of identities regardless (see the Data section of the OSF page), our results are unlikely to be significantly impacted by this confound. Nevertheless, future research may wish to use a dataset containing exclusively unfamiliar faces if one is available.

Another factor to consider is the possible interference of the own-race bias, given that all of our identities depicted Caucasian faces. We did not account for race when constructing our methodology; however, while face processing and identification may have suffered for non-Caucasian participants, our results do not seem to differ from what we would expect if the own-race bias was absent. True, being presented with an other-race face would make single image identifications more difficult (references); however, this is already a difficult task for own-race faces compared to multiple image identifications (reference), and so the relative performance with single images is expected. One might presume that the own-race bias would have made it increasingly difficult to process faces at more rapid image rates, due to a lack of holistic processing with other-race faces generally (reference), and the fact that holistic processing seems necessary for rapid gist perception (reference). However, if this was particularly influential, then we would not have observed an overall linear increase in recognition as image rate increased. In fact, given that we observed our pattern of results even despite the own-race bias, this may argue towards the strength of this methodology in facilitating face identification.

While our study does not elaborate on the nature of inverted face recognition - whether inverted face recognition is poorer due to a lack of experience, or because it is processed as a non-face object - our results pose interesting questions for future research regardless. If the experience account of inverted face recognition is correct, then this RSVP methodology may be useful for increasing identification accuracy for complex objects that we are less familiar with, possibly for non-face objects [fix up phrasing buddy]. Many forensic or medical disciplines, for example, depend on making identifications or diagnoses based on accurate assessments of broadly unfamiliar, complex stimuli, such as fingerprints, shoeprints, or mammograms. While our RSVP methodology may not be useful for practical case work, a similar methodology may be useful in designing training exercises to potentially streamline the development of expertise among novices. Previous research, for example, has suggested that non-analytic processing, one of the hallmarks of expertise in fingerprint identification, derives from having vast exposure to many different fingerprints over time (Searston & Tangen, 2017a, 2017b; Thompson & Tangen, 2014) and subsequently argues for incorporating exposure to varying instances into training, rather than an exclusive focus on deliberate analysis of single instances case by case (Thompson & Tangen, 2014). If our results do generalise to other complex, unfamiliar visual categories, this may be an efficient method to do so.

If these findings were to be replicated or extended in different contexts, they may reveal benefits of image presentation rate beyond face recognition for other domains of perceptual expertise. Given that prior exposure to variation seems to increase recognition performance when controlling for time, the identification decisions of counterfeit investigators, passport officers, various medical practitioners, and other professionals who rely on their perceptual expertise, may benefit from accumulating as much exposure as possible to varying examples within their domain. Future research may look to improve expert identification decisions by optimising the advantages of viewing time and exposure to variation in a range of given fields.



\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
